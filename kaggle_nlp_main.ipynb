{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:16:45.472577Z","iopub.status.busy":"2022-08-21T10:16:45.472156Z","iopub.status.idle":"2022-08-21T10:16:49.419007Z","shell.execute_reply":"2022-08-21T10:16:49.417923Z","shell.execute_reply.started":"2022-08-21T10:16:45.472489Z"},"id":"Bvwr9-mC5BYN","outputId":"b49be198-2368-4ac2-9479-b535bc604889","trusted":true},"outputs":[],"source":["# !pip install tensorflow-gpu==2.6.*\n","import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmiZLKK5PJ36","outputId":"970510f5-7867-4705-d121-ea8405e8c821","trusted":true},"outputs":[],"source":["!nvidia-smi\n","!nvcc --version"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:20:22.750782Z","iopub.status.busy":"2022-08-21T10:20:22.750413Z","iopub.status.idle":"2022-08-21T10:20:39.445580Z","shell.execute_reply":"2022-08-21T10:20:39.444434Z","shell.execute_reply.started":"2022-08-21T10:20:22.750729Z"},"id":"0y1Vq65s5BYm","outputId":"867ef4f0-19d7-4b89-c3fb-58f7277fde13","trusted":true},"outputs":[],"source":["!pip install textstat xgboost gensim==4.2.0"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:20:48.045814Z","iopub.status.busy":"2022-08-21T10:20:48.045410Z","iopub.status.idle":"2022-08-21T10:20:49.331243Z","shell.execute_reply":"2022-08-21T10:20:49.330304Z","shell.execute_reply.started":"2022-08-21T10:20:48.045781Z"},"id":"TGuhjG515BYx","trusted":true},"outputs":[],"source":["import pickle\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","import re\n","import datetime\n","import time\n","import string\n","import statistics\n","import textstat\n","from bs4 import BeautifulSoup\n","from collections import Counter\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","from nltk.corpus import wordnet\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","from gensim.models import KeyedVectors\n","from gensim.models.keyedvectors import Word2VecKeyedVectors\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","import xgboost as xgb"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:21:21.741143Z","iopub.status.busy":"2022-08-21T10:21:21.740734Z","iopub.status.idle":"2022-08-21T10:21:21.749481Z","shell.execute_reply":"2022-08-21T10:21:21.748440Z","shell.execute_reply.started":"2022-08-21T10:21:21.741110Z"},"id":"zv4ugAPa5BY1","trusted":true},"outputs":[],"source":["import nltk\n","# nltk.download('punkt') If needed\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","from bs4 import BeautifulSoup ## handles html\n","import re ## provides regular expressions functionality\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T11:02:20.939462Z","iopub.status.busy":"2022-08-21T11:02:20.938855Z","iopub.status.idle":"2022-08-21T11:02:20.945466Z","shell.execute_reply":"2022-08-21T11:02:20.944471Z","shell.execute_reply.started":"2022-08-21T11:02:20.939428Z"},"id":"3bXicNiN5BZE","trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Concatenate, Flatten ,Dense, Embedding, LSTM, GRU, Bidirectional, BatchNormalization, Dropout\n","from tensorflow.keras.initializers import Constant\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eA1fSKwRVfmw","outputId":"3d7154fe-bfb9-4a6e-be9d-d346848a4827"},"outputs":[],"source":["#read data\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:21:29.414153Z","iopub.status.busy":"2022-08-21T10:21:29.413350Z","iopub.status.idle":"2022-08-21T10:21:32.388134Z","shell.execute_reply":"2022-08-21T10:21:32.387124Z","shell.execute_reply.started":"2022-08-21T10:21:29.414118Z"},"id":"MuPIoafn5BZI","trusted":true},"outputs":[],"source":["train = pd.read_csv(\"../input/adamssose22/train.csv\", sep=\",\", encoding=\"utf-8\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:21:32.390351Z","iopub.status.busy":"2022-08-21T10:21:32.390005Z","iopub.status.idle":"2022-08-21T10:21:33.986378Z","shell.execute_reply":"2022-08-21T10:21:33.985375Z","shell.execute_reply.started":"2022-08-21T10:21:32.390316Z"},"id":"AFmfToJKWMTl","trusted":true},"outputs":[],"source":["test = pd.read_csv(\"../input/adamssose22/test.csv\", sep=\",\", encoding=\"utf-8\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wQLZAFz5BZK"},"outputs":[],"source":["train_review = pd.read_csv(\"drive/MyDrive/reviews.csv\", sep=\",\", encoding=\"utf-8\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZezACgz5BZN","outputId":"58d25cbf-e29a-4e23-8201-c8cbc5674458"},"outputs":[],"source":["train_review.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vH9en46p5BZP","outputId":"f3f8bb5f-bd60-4ded-cdb9-23fcf4cf879a"},"outputs":[],"source":["train_review.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDhz4JYG5BZV","outputId":"68aec305-acc2-47cd-9e01-a4c07b427bb8"},"outputs":[],"source":["train.columns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LL6rVfPw5BZX","outputId":"a6339dff-c476-48a7-f521-21f5a4eedc3f"},"outputs":[],"source":["train[train.host_id == train.host_id[2]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohXrqq375BZa","outputId":"33593af2-a5fc-4586-a8cb-c150c547bd14"},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2H4QSZ8b5BZd","outputId":"2603c978-8b20-4b7b-ae6c-218d26199ea7"},"outputs":[],"source":["# Show target distribution\n","plt.hist(train.price)\n","plt.xlabel('Price')\n","plt.title('Price distribution')\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTpkxlmh5BZf","outputId":"5c9c16d4-8954-4c2e-bfbb-beff10fbe702"},"outputs":[],"source":["train.isnull().sum()/55284 * 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Fgvbd9A5BZh","outputId":"af911c1e-a53c-4918-da1f-178d8d7ca9a4"},"outputs":[],"source":["\n","train['reviews_per_month'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"py7z_l915BZ4"},"outputs":[],"source":["train_duplicate = train.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSHvFWFY5BZ7","outputId":"1a927bea-108a-412e-e826-9c24c29d7959"},"outputs":[],"source":["train_duplicate[train_duplicate.duplicated()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMpgJU6S5BaC","outputId":"524e9166-d578-428c-f47f-7fc9eca8379a"},"outputs":[],"source":["train.host_response_rate.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7CkeLYJ5BaJ","outputId":"9ebaba11-9a37-4136-a42b-74ea08bb7e00"},"outputs":[],"source":["train['host_response_time'].isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-EFN2dG5BaL","outputId":"7a529df8-b286-46d6-a6ab-c57137ee05e7"},"outputs":[],"source":["\n","train['zipcode'].mode()"]},{"cell_type":"markdown","metadata":{"id":"x6kQC-i15BaO"},"source":["## Cleaning test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4Mr-7ic5BaW","outputId":"9fd18325-ad2a-4258-c04d-0772e8b98b9d","scrolled":true},"outputs":[],"source":["test['host_is_superhost'].fillna(0,inplace = True) #replacing NA with 0, assuming 0 is false value. \n","test.host_is_superhost[test.host_is_superhost == \"t\"] = 1 #replacing \"t\" with 1\n","test.host_is_superhost[test.host_is_superhost == \"f\"] = 0 #replacing \"f\" with 0\n","test[\"host_is_superhost\"] = test[\"host_is_superhost\"].astype(\"int64\") #converting host_is_superhost to boolean datatype\n","test['host_has_profile_pic'].fillna(0,inplace = True) #replacing NA with 0, assuming 0 is false value. \n","test.host_has_profile_pic[test.host_has_profile_pic == \"t\"] = 1 #replacing \"t\" with 1\n","test.host_has_profile_pic[test.host_has_profile_pic == \"f\"] = 0 #replacing \"f\" with 0\n","test[\"host_has_profile_pic\"] = test[\"host_has_profile_pic\"].astype(\"int64\") #converting host_is_superhost to boolean datatype\n","\n","test['host_identity_verified'].fillna(0,inplace = True) #replacing NA with 0, assuming 0 is false value. \n","test.host_identity_verified[test.host_identity_verified == \"t\"] = 1 #replacing \"t\" with 1\n","test.host_identity_verified[test.host_identity_verified == \"f\"] = 0 #replacing \"f\" with 0\n","test[\"host_identity_verified\"] = test[\"host_identity_verified\"].astype(\"int64\") #converting host_is_superhost to boolean datatyp\n","test['host_total_listings_count'].fillna(test['host_total_listings_count'].mean(),inplace = True) #replacing NA with mean of 'host_total_listings_count']\n","test['zipcode'].fillna('E1',inplace = True) #replacing NA with most frequently occuring zipcode \n","test['bathrooms'].fillna(test['bathrooms'].mean(),inplace = True) #replacing NA with most frequently occuring zipcode \n","test['bedrooms'].fillna(test['bedrooms'].mean(),inplace = True) #replacing NA with most frequently occuring zipcode \n","test['beds'].fillna(test['beds'].mean(),inplace = True) #replacing NA with most frequently occuring zipcode \n","\n","test['review_scores_rating'].fillna(test['review_scores_rating'].mean(),inplace = True)\n","test['review_scores_accuracy'].fillna(test['review_scores_accuracy'].mean(),inplace = True)\n","test['review_scores_cleanliness'].fillna(test['review_scores_cleanliness'].mean(),inplace = True)\n","test['review_scores_checkin'].fillna(test['review_scores_checkin'].mean(),inplace = True)\n","test['review_scores_communication'].fillna(test['review_scores_communication'].mean(),inplace = True)\n","test['review_scores_location'].fillna(test['review_scores_location'].mean(),inplace = True)\n","test['review_scores_value'].fillna(test['review_scores_value'].mean(),inplace = True)\n","test['reviews_per_month'].fillna(test['reviews_per_month'].mean(),inplace = True)\n","\n","test['summary'].fillna('empty',inplace = True)\n","test[\"property_type\"] = test[\"property_type\"].astype(\"category\") \n","test[\"room_type\"] = test[\"room_type\"].astype(\"category\") \n","test[\"bed_type\"] = test[\"bed_type\"].astype(\"category\") \n","test['host_response_time'].fillna(\"missing\",inplace = True)\n","test[\"host_response_time\"] = test[\"host_response_time\"].astype(\"category\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mywJ0mRhxozI"},"outputs":[],"source":["test['summary'].fillna('empty',inplace = True)\n","test['name'].fillna('empty',inplace = True)\n","test['space'].fillna('empty',inplace = True)\n","test['description'].fillna('empty',inplace = True)\n","test['neighborhood_overview'].fillna('empty',inplace = True)\n","test['transit'].fillna('empty',inplace = True)\n","test['house_rules'].fillna('empty',inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3iBTBx45Bac"},"outputs":[],"source":["test[\"host_since\"] = test[\"host_since\"].astype(\"datetime64[ns]\")\n","test[\"host_since\"].fillna(pd.to_datetime('2015-05-21'),inplace = True)\n","test['host_days'] = (datetime.datetime.today() - test['host_since'])//np.timedelta64(1,'D')   \n","test['host_days'] = test['host_days']/365\n","x_test_dummies = pd.get_dummies(test, columns = ['host_response_time','room_type','bed_type'], drop_first=True)          \n","x_test_dummies = x_test_dummies.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])\n","x_test_dummies.drop([\"host_id\",\"latitude\",\"longitude\"], inplace=True, axis=1)"]},{"cell_type":"markdown","metadata":{"id":"CZJSJs0_5Bag"},"source":["## Cleaning Train Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJBTlaP-5Bak","outputId":"ff63bf22-7762-4fdc-f34d-4435c4caa81d"},"outputs":[],"source":["train['host_is_superhost'].fillna(0,inplace = True) #replacing NA with 0, assuming 0 is false value. \n","train.host_is_superhost[train.host_is_superhost == \"t\"] = 1 #replacing \"t\" with 1\n","train.host_is_superhost[train.host_is_superhost == \"f\"] = 0 #replacing \"f\" with 0\n","train[\"host_is_superhost\"] = train[\"host_is_superhost\"].astype(\"int64\") #converting host_is_superhost to boolean datatype\n","train['host_has_profile_pic'].fillna(0,inplace = True) #replacing NA with 0, assuming 0 is false value. \n","train.host_has_profile_pic[train.host_has_profile_pic == \"t\"] = 1 #replacing \"t\" with 1\n","train.host_has_profile_pic[train.host_has_profile_pic == \"f\"] = 0 #replacing \"f\" with 0\n","train[\"host_has_profile_pic\"] = train[\"host_has_profile_pic\"].astype(\"int64\") #converting host_is_superhost to boolean datatype\n","\n","train['host_identity_verified'].fillna(0,inplace = True) #replacing NA with 0, assuming 0 is false value. \n","train.host_identity_verified[train.host_identity_verified == \"t\"] = 1 #replacing \"t\" with 1\n","train.host_identity_verified[train.host_identity_verified == \"f\"] = 0 #replacing \"f\" with 0\n","train[\"host_identity_verified\"] = train[\"host_identity_verified\"].astype(\"int64\") #converting host_is_superhost to boolean datatyp\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2jx7Rn45Ban","outputId":"cd5d2d37-b91e-4fa9-9d67-b6ed8c339aaa"},"outputs":[],"source":["train['bathrooms'].isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDCMlRRx5Baq"},"outputs":[],"source":["train['host_total_listings_count'].fillna(train['host_total_listings_count'].mean(),inplace = True) #replacing NA with mean of 'host_total_listings_count']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeBi8fs65Baq","outputId":"74d7e2a0-1eef-46bf-e235-f9903761750c"},"outputs":[],"source":["train['neighbourhood'].mode()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJ2o-SkU5Bar"},"outputs":[],"source":["train['neighbourhood'].fillna('City of Westminster',inplace = True) #replacing NA with most frequently occuring neighbourhood"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXjxM5zK5Bar","outputId":"9208c25e-2292-4943-c9cc-88cd4fcaeec7"},"outputs":[],"source":["train['zipcode'].mode()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5c0oHnG5Bas"},"outputs":[],"source":["train['zipcode'].fillna('E1',inplace = True) #replacing NA with most frequently occuring zipcode "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PyYKQnc5Bas"},"outputs":[],"source":["train['bathrooms'].fillna(train['bathrooms'].mean(),inplace = True) #replacing NA with most frequently occuring zipcode "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_nFcZHw55Bat"},"outputs":[],"source":["train['bedrooms'].fillna(train['bedrooms'].mean(),inplace = True) #replacing NA with most frequently occuring zipcode "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2DoN12-5Bat"},"outputs":[],"source":["train['beds'].fillna(train['beds'].mean(),inplace = True) #replacing NA with most frequently occuring zipcode "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19KooAcy5Bau"},"outputs":[],"source":["train['review_scores_rating'].fillna(train['review_scores_rating'].mean(),inplace = True)\n","train['review_scores_accuracy'].fillna(train['review_scores_accuracy'].mean(),inplace = True)\n","train['review_scores_cleanliness'].fillna(train['review_scores_cleanliness'].mean(),inplace = True)\n","train['review_scores_checkin'].fillna(train['review_scores_checkin'].mean(),inplace = True)\n","train['review_scores_communication'].fillna(train['review_scores_communication'].mean(),inplace = True)\n","train['review_scores_location'].fillna(train['review_scores_location'].mean(),inplace = True)\n","train['review_scores_value'].fillna(train['review_scores_value'].mean(),inplace = True)\n","train['reviews_per_month'].fillna(train['reviews_per_month'].mean(),inplace = True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIVeQrtm5Baw"},"outputs":[],"source":["train['summary'].fillna('empty',inplace = True)\n","train[\"property_type\"] = train[\"property_type\"].astype(\"category\") \n","train[\"room_type\"] = train[\"room_type\"].astype(\"category\") \n","train[\"bed_type\"] = train[\"bed_type\"].astype(\"category\") \n","train['host_response_time'].fillna(\"missing\",inplace = True)\n","train[\"host_response_time\"] = train[\"host_response_time\"].astype(\"category\") \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvbu4_ui5Bax"},"outputs":[],"source":["train['summary'].fillna('empty',inplace = True)\n","train['name'].fillna('empty',inplace = True)\n","train['space'].fillna('empty',inplace = True)\n","train['description'].fillna('empty',inplace = True)\n","train['neighborhood_overview'].fillna('empty',inplace = True)\n","train['transit'].fillna('empty',inplace = True)\n","train['house_rules'].fillna('empty',inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0vB-iv1UGG8","outputId":"2831be2d-5e7b-4a7d-e08a-64700419c2b9"},"outputs":[],"source":["train[\"host_since\"].mode()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vFfIatfVTmwZ"},"outputs":[],"source":["import pickle\n","\n","train.to_pickle('train.pkl')\n","test.to_pickle('test.pkl')"]},{"cell_type":"markdown","metadata":{"id":"vK7RZIql5Baz"},"source":["## Cleaning Text Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuOy5l1c5Ba0"},"outputs":[],"source":["def remove_whitespace(text):\n","    \"\"\" Function to remove whitespace (tabs, newlines). \"\"\"\n","    return ' '.join(text.split())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hq-Nia0b5Ba0"},"outputs":[],"source":["from bs4 import BeautifulSoup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNzTT6Eg5Ba1"},"outputs":[],"source":["def remove_punctuation_and_casing(text):\n","    \"\"\"\n","    Function to remove the punctuation, upper casing and words that include\n","    non-alphanumeric characters.\n","    \"\"\"\n","    chars = '!\\\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n","    text = text.translate(str.maketrans(chars, ' ' * len(chars)))\n","    return ' '.join([word.lower() for word in text.split() if word.isalpha()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DN0apF2e5Ba2","outputId":"6b7cd391-96a9-41ad-bafd-8f6c79c0bfac"},"outputs":[],"source":["from nltk.corpus import stopwords\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","\n","english_stopwords = stopwords.words('english')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVkbQY2n5Ba2"},"outputs":[],"source":["def remove_stopwords(text):\n","    \"\"\" Function to remove stopwords. \"\"\"\n","    return ' '.join([word for word in str(text).split() if word not in english_stopwords])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QHQjTJ55Ba3"},"outputs":[],"source":["from nltk.corpus import wordnet\n","\n","def get_wordnet_pos(word):\n","    \"\"\"Helper function that calls the POS tagger for an input word and return a code that can be used for lemmatization\"\"\"\n","    # Extract the first letter of the POS tag (see the above example to understand the output coming from pos_tag)\n","    tag = nltk.pos_tag([word])[0][1][0].upper()  \n","    # Dictionary to map these letters to wordnet codes that the lemmatizer understands\n","    tag_dict = {\"J\": wordnet.ADJ,\n","                \"N\": wordnet.NOUN,\n","                \"V\": wordnet.VERB,\n","                \"R\": wordnet.ADV}\n","    return tag_dict.get(tag, wordnet.NOUN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmoaChQb5Ba5"},"outputs":[],"source":["def text_cleaning(documents):\n","    \"\"\"\n","    Function for standard NLP pre-processing including removal of html tags,\n","    whitespaces, non-alphanumeric characters, and stopwords. Emoticons are\n","    converted to text that reflects their meaning. Words are subject to\n","    lemmatization using their POS tags.\n","    \"\"\"\n","    cleaned_text = []  # our output will be a list of documents\n","    lemmatizer = WordNetLemmatizer()\n","    \n","    print('Processing input array with {} elements...'.format(documents.shape[0]))\n","    counter = 0\n","    \n","    for doc in documents:\n","        text = BeautifulSoup(doc).get_text() # remove html content\n","        text = remove_whitespace(text) # remove whitespaces\n","        text = remove_punctuation_and_casing(text) # remove punctuation and casing\n","        text = remove_stopwords(text) # remove stopwords\n","        text = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in text.split()]) # lemmatize each word\n","        \n","        cleaned_text.append(text)\n","\n","        if (counter > 0 and counter % 50 == 0):\n","            print('Processed {} documents'.format(counter))\n","            \n","        counter += 1\n","        \n","    return cleaned_text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBk7DUGu5Ba6","outputId":"bc511a6c-3afa-4a7c-8ac7-8bc4dee8f451"},"outputs":[],"source":["nltk.download('stopwords') ## to identify stopwords \n","nltk.download('averaged_perceptron_tagger') ## for part-of-speech tagging (used for lemmatization)\n","nltk.download('omw-1.4')\n","nltk.download('wordnet')\n","\n","# Lemmatize with POS Tag (Parts of Speech tagging)\n","def get_wordnet_pos(word):\n","    \"\"\"Map POS tag to first character for lemmatization\"\"\"\n","    tag = nltk.pos_tag([word])[0][1][0].upper()\n","    tag_dict = {\"J\": wordnet.ADJ,\n","                \"N\": wordnet.NOUN,\n","                \"V\": wordnet.VERB,\n","                \"R\": wordnet.ADV}\n","\n","    return tag_dict.get(tag, wordnet.NOUN)\n","\n","## function to clean text data\n","def clean_reviews(df):\n","    \"\"\" Standard NLP pre-processing chain including removal of html tags, non-alphanumeric characters, and stopwords.\n","        Words are subject to lemmatization using their POS tags, which are determind using WordNet. \n","    \"\"\"\n","    reviews = []\n","\n","    lemmatizer = WordNetLemmatizer()\n","    \n","    print('*' * 40)\n","    print('Cleaning {} movie reviews.'.format(df.shape[0]))\n","    counter = 0\n","    for review in df:\n","        \n","        # remove html content\n","        review_text = BeautifulSoup(review).get_text()\n","        \n","        # remove non-alphabetic characters\n","        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n","    \n","        # tokenize the sentences with all capital letters transformed to lower case\n","        words = word_tokenize(review_text.lower())\n","  \n","        # filter stopwords\n","        words = [w for w in words if w not in stopwords.words(\"english\")]\n","        \n","        # lemmatize each word to its lemma\n","        lemma_words =[lemmatizer.lemmatize(i, get_wordnet_pos(i)) for i in words]\n","    \n","        reviews.append(lemma_words)\n","              \n","        if (counter > 0 and counter % 5000 == 0):\n","            print('Processed {} reviews'.format(counter))\n","            \n","        counter += 1\n","        \n","    print('DONE')\n","    print('*' * 40)\n","\n","    return(reviews) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSbZQP1K5Ba7","outputId":"c175d7b5-141c-4b55-b951-a07e090803a1"},"outputs":[],"source":["nltk.download('punkt')\n","summary_clean = clean_reviews(train.summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cPvVLSic5Ba8"},"outputs":[],"source":["train[\"summary_clean\"] = summary_clean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HEXw3_KV5Ba8"},"outputs":[],"source":["train.summary_clean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FtATwNlf5Ba-"},"outputs":[],"source":["train.summary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqphX9Wa5Ba_"},"outputs":[],"source":["#summary\tspace\tdescription, neighborhood_overview\ttransit\thouse_rules\n","#'name','summary','space','description','experiences_offered','neighborhood_overview','transit','house_rules'\n","text_processed = text_cleaning(train.experiences_offered)\n","print(text_processed)"]},{"cell_type":"markdown","metadata":{"id":"6nVsvK355BbA"},"source":["# Modeling"]},{"cell_type":"markdown","metadata":{"id":"U1sKt2Tn5BbC"},"source":["### using only numerical data and FNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQ2ZOVeZ5BbD"},"outputs":[],"source":["train[\"host_since\"].mode()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9sYAmMUZ5BbF"},"outputs":[],"source":["train[\"host_since\"] = train[\"host_since\"].astype(\"datetime64[ns]\")\n","train[\"host_since\"].fillna(pd.to_datetime('2015-05-21'),inplace = True)\n","train['host_days'] = (datetime.datetime.today() - train['host_since'])//np.timedelta64(1,'D')   \n","train['host_days'] = train['host_days']/365"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUuMrs7-5BbH"},"outputs":[],"source":["x_train_dummies = pd.get_dummies(train, columns = ['host_response_time','room_type','bed_type'], drop_first=True)          \n","x_train_dummies = x_train_dummies.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])\n","x_train_dummies.drop([\"host_id\",\"latitude\",\"longitude\"], inplace=True, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIZLpZ-m5BbL"},"outputs":[],"source":["x_train_dummies[\"summary_clean\"] = summary_clean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yg-v4mNH5BbO"},"outputs":[],"source":["x_train_dummies.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4srmiVV45BbP"},"outputs":[],"source":["y = x_train_dummies[['price']]\n","x_train_dummies.pop(\"price\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKYydA_35BbQ"},"outputs":[],"source":["x_train_dummies.drop([\"summary_clean\"], inplace=True, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPGOp9OH5BbS"},"outputs":[],"source":["seed=888\n","X_train, X_test, y_train, y_test = train_test_split(x_train_dummies, y, test_size=0.30, random_state=seed)\n","    \n","print (X_train.shape)\n","print(y_train.shape) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo-xob-I5BbV"},"outputs":[],"source":["nb_units = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTMMrCfH5BbW"},"outputs":[],"source":[" y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72at6RIa5Bba"},"outputs":[],"source":["x_train_dummies.shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAK8tUzw5Bbb","outputId":"ff3d7846-cd5d-44ae-b90d-f5f82e96cac7"},"outputs":[],"source":["inputs = layers.Input(shape=(x_train_dummies.shape[1],))\n","layer1 = layers.Dense(nb_units,  activation='relu', #activation function\n","                kernel_initializer=keras.initializers.he_normal(seed=seed), #initialisation of weights, \n","                bias_initializer='zeros')(inputs)\n","layer2 = layers.Dense(nb_units,activation='relu',kernel_initializer=keras.initializers.he_normal(seed=seed),bias_initializer='zeros')(layer1)\n","predictions = layers.Dense(1, activation='relu')(layer2)\n","\n","model = keras.Model(inputs=inputs, outputs=predictions)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bk3vjFIZ5Bbc"},"outputs":[],"source":["model.compile(optimizer='rmsprop', \n","    loss='mse', \n","    metrics=['mae']) \n","    \n","history = model.fit(\n","    X_train, \n","    y_train, \n","    epochs = 5, \n","    batch_size=1,\n","    validation_data=(X_test, y_test),\n","    verbose = 0) \n","\n","## make predictions\n","pred_ff_train = model.predict(X_train)\n","pred_ff_test = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e8qH4aD5Bbd"},"outputs":[],"source":["?model.compile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjLWmnt75Bbe"},"outputs":[],"source":["pred_ff_test = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7QKyFSq5Bbf"},"outputs":[],"source":["pred_ff_test = model.predict(x_test_dummies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJE6GzSI5Bbf","outputId":"f5317762-5846-4025-d143-8ac3b180bf25"},"outputs":[],"source":["test.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jyPrquzV5Bbg","outputId":"f41f6ed5-ead8-48c7-c7c8-93e86a2f6f7d"},"outputs":[],"source":["pred_ff_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsZG3v8i5Bbh","outputId":"acd24cb7-1796-44d5-f0a6-9ece18186b9f"},"outputs":[],"source":["loss = history.history[\"mae\"] \n","val_loss = history.history[\"val_mae\"] \n","epochs = range(1, len(loss) + 1) \n","plt.figure()\n","plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n","plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n","plt.title(\"Training and validation MAE\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLBPmBXQ5Bbj"},"outputs":[],"source":["score = model.evaluate(X_test, y_test, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUrNbrwu5Bbk","outputId":"bec0db4d-8156-49b6-cb3b-6056bdfbcf30"},"outputs":[],"source":["print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhuHJRfs5Bbn"},"outputs":[],"source":["from IPython.display import FileLink, FileLinks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfZu9lI55Bbo","outputId":"be009cd9-b433-403e-b76f-31ff04cfe7cd"},"outputs":[],"source":["pred_kaggle = pd.DataFrame(pred_ff_test, columns=['price'], index = test.listing_id)\n","pred_kaggle.to_csv('C:/Users/ASUS/Desktop/pred_kaggle.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2X1sZy4_5Bbp"},"outputs":[],"source":["mean_squared_error(y_train,pred_ff_train)\n","pred_ff_test = model.predict(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAnUWyc-5Bbr"},"outputs":[],"source":["print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,pred_ff_test))  \n","print('Mean Squared Error:', metrics.mean_squared_error(y_test,pred_ff_test))  \n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,pred_ff_test)))"]},{"cell_type":"markdown","metadata":{"id":"CdpvPKp-5Bb3"},"source":["## modeling using only summary column and fnn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQQM6nPP5Bb4"},"outputs":[],"source":["import io\n","import re\n","import string\n","import pandas as pd\n","import gensim\n","from gensim.models import Word2Vec  \n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7o32uOdd5Bb4"},"outputs":[],"source":["Xclean_train, Xclean_val, y_train, y_val = train_test_split(train['summary'], train['price'], test_size = 0.2, random_state = 888)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApL2z1HM5Bb4"},"outputs":[],"source":["X_train = Xclean_train.to_numpy()\n","X_val = Xclean_val.to_numpy()\n","y_train = y_train.to_numpy()\n","y_val = y_val.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h9DEAXiO5Bb5"},"outputs":[],"source":["Xclean_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTrWVRgR5Bb6"},"outputs":[],"source":["def our_standardization(text_data):\n","  lowercase = tf.strings.lower(text_data) # convert to lowercase\n","  remove_html = tf.strings.regex_replace(lowercase, '<br />', ' ') # remove HTML tags\n","  pattern_remove_punctuation = '[%s]' % re.escape(string.punctuation) # pattern to remove punctuation\n","  remove_punct = tf.strings.regex_replace(remove_html, pattern_remove_punctuation, '') # apply pattern\n","  remove_double_spaces = tf.strings.regex_replace(remove_punct, '\\s+', ' ') # remove double space\n","  return remove_double_spaces"]},{"cell_type":"markdown","metadata":{"id":"qvEsknaKNAeF"},"source":["###### Emergency back up of data to put in NN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_wMKhtFMyf-","outputId":"1f0a77c6-af21-4937-e79e-f04091d7a3fc"},"outputs":[],"source":["\n","\n","X_train_bk = X_train.copy()\n","y_train_bk = y_train.copy()\n","X_test_bk = X_test.copy()\n","y_test_bk = y_test.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ofUVwRUH5Bb9","outputId":"99f139bf-b23b-4901-df9d-7513e8e76c65"},"outputs":[],"source":["# Create a simple model to use word embeddings\n","from tensorflow.keras import Sequential\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","\n","def make_model():\n","  # Define the size of the vocabulary and the max number of words in a sequence\n","  vocab_size = 10000\n","  seq_length = 100\n","\n","  # Create a vectorization layer\n","  vectorize_layer = TextVectorization(\n","      standardize = our_standardization,\n","      max_tokens = vocab_size,\n","      output_sequence_length = seq_length\n","      )\n","\n","  vectorize_layer.adapt(X_train)\n","  embedding_dim = 16\n","  model = Sequential([\n","                    vectorize_layer,\n","                    layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"), \n","                    layers.GlobalAveragePooling1D(), # each sample is reduced to the average of the word embeddings\n","                    layers.Dense(1, activation='relu')\n","                  ])\n","  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae','mse'])\n","  return model\n","\n","\n","model = make_model()\n","  \n","  \n","  \n","history = model.fit(\n","      X_train, \n","      y_train, \n","      epochs = 5, \n","      batch_size=64,\n","      validation_data=(X_test, y_test),\n","      verbose = 1\n","      ) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_DWVp_M5Bb-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjN_omb35Bb_"},"outputs":[],"source":["pred_ff_train = model.predict(X_train)\n","pred_ff_test = model.predict(X_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbPjamEB5BcA"},"outputs":[],"source":["pred_ff_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vIvALJwO5BcB"},"outputs":[],"source":["pred_ff_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-1728CR5BcC"},"outputs":[],"source":["y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03dx30Vl5BcD"},"outputs":[],"source":["y_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"erIx3tmM5BcE"},"outputs":[],"source":["X_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VT03NN3u5BcF"},"outputs":[],"source":["print('Mean Absolute Error:', metrics.mean_absolute_error(y_val,pred_ff_test))  \n","print('Mean Squared Error:', metrics.mean_squared_error(y_val,pred_ff_test))  \n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val,pred_ff_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbj1xXgz5BcF"},"outputs":[],"source":["test_summary = test['summary'].to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdCqANWG5BcG"},"outputs":[],"source":["test_summary.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDpjnbUS5BcG"},"outputs":[],"source":["pred_ff_kaggle = model.predict(test_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOcTpbRv5BcI"},"outputs":[],"source":["pred_kaggle_summary = pd.DataFrame(pred_ff_kaggle, columns=['price'], index = test.listing_id)\n","pred_kaggle_summary.to_csv('C:/Users/ASUS/Desktop/pred_kaggle_summary.csv')"]},{"cell_type":"markdown","metadata":{"id":"5LpYzrFo5BcJ"},"source":["## LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIfAKrGx5BcJ","outputId":"f41252fd-029f-4ff9-dc2a-5a2e10655b0c"},"outputs":[],"source":["vocab_size = 10000\n","seq_length = 500\n","\n","# Create a vectorization layer\n","vectorize_layer = TextVectorization(\n","    standardize = our_standardization,\n","    max_tokens = vocab_size,\n","    output_sequence_length = seq_length\n","    )\n","vectorize_layer.adapt(X_train)\n","## Transform sequences of words to seq of integers and labels to tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sadag8-b5BcK"},"outputs":[],"source":["X_train = vectorize_layer(X_train)\n","X_val = vectorize_layer(X_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lL43FMMV5BcL"},"outputs":[],"source":["test_summary = vectorize_layer(test_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EMpQ_Xgc5BcL","outputId":"4d2658ac-34bb-49a5-e18d-f5e5b3ccf734"},"outputs":[],"source":["# Create model with LSTM\n","emb_size = 32\n","rnn_units = 16\n","input = tf.keras.Input(shape=(seq_length,), dtype=\"int64\") \n","emb = layers.Embedding(input_dim=vocab_size, output_dim=emb_size, mask_zero=True)(input) \n","x = layers.LSTM(rnn_units)(emb)\n","output = layers.Dense(1, activation=\"relu\")(x)\n","model = tf.keras.Model(input, output) \n","\n","model.compile(optimizer='rmsprop', \n","    loss='mse', \n","    metrics=['mae'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VGfk2N2G5BcM"},"outputs":[],"source":["y_train = tf.convert_to_tensor(y_train)\n","y_val = tf.convert_to_tensor(y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oi0Ct_Hh5BcM","outputId":"6f3dfc65-6e14-4e48-b5b8-19745a119d51"},"outputs":[],"source":["story = model.fit(\n","    X_train, \n","    y_train, \n","    validation_data=(X_val, y_val),\n","    epochs = 30,\n","    batch_size = 128)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoKLR_F45BcN","outputId":"01578710-151d-4fbc-a9a0-0f18c684d112"},"outputs":[],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrS2okT-5BcP","outputId":"e8e8f656-50ce-46fb-b835-e25bceb083b9"},"outputs":[],"source":["pred_ff_train = model.predict(X_train)\n","pred_ff_test = model.predict(X_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQGmAN8S5BcP","outputId":"1d984eab-b385-4503-ec11-490d425b65ba"},"outputs":[],"source":["print('Mean Absolute Error:', metrics.mean_absolute_error(y_val,pred_ff_test))  \n","print('Mean Squared Error:', metrics.mean_squared_error(y_val,pred_ff_test))  \n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val,pred_ff_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"645MxeqX5BcQ","outputId":"859b2638-5db8-4051-bf79-097acbf39c0e"},"outputs":[],"source":["pred_ff_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pa576O7G5BcQ","outputId":"d94d3d4c-399d-4803-e655-eb653ddb9158"},"outputs":[],"source":["pred_ff_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0U74HF735BcQ","outputId":"1cec4a7c-99c3-4322-e4a2-b0e2f8694910"},"outputs":[],"source":["pred_ff_kaggle = model.predict(test_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bU2fSzFo5BcR"},"outputs":[],"source":["pred_kaggle_summary = pd.DataFrame(pred_ff_kaggle, columns=['price'], index = test.listing_id)\n","pred_kaggle_summary.to_csv('C:/Users/ASUS/Desktop/pred_kaggle_summary.csv')"]},{"cell_type":"markdown","metadata":{"id":"3yyLnMye5BcR"},"source":["## LSTM"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T12:08:25.228858Z","iopub.status.busy":"2022-08-21T12:08:25.228441Z","iopub.status.idle":"2022-08-21T12:08:25.251204Z","shell.execute_reply":"2022-08-21T12:08:25.250280Z","shell.execute_reply.started":"2022-08-21T12:08:25.228824Z"},"id":"AXLd6YufyO0E","trusted":true},"outputs":[],"source":["train_desc = train['description'].fillna('empty')\n","train_ngbr = train['neighborhood_overview'].fillna('empty')\n","\n","y_train = train['price']"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T12:08:36.375059Z","iopub.status.busy":"2022-08-21T12:08:36.374668Z","iopub.status.idle":"2022-08-21T12:08:36.380855Z","shell.execute_reply":"2022-08-21T12:08:36.379818Z","shell.execute_reply.started":"2022-08-21T12:08:36.375027Z"},"id":"rYaQferdbXTJ","outputId":"08fbe684-16c5-495c-a155-7607859ba140","trusted":true},"outputs":[],"source":["print(len(train_desc), len(train_ngbr), len(y_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhhXJXfd0CfK","outputId":"9540095b-d54b-4a34-c3d1-0d503ff0f7df"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:21:55.322484Z","iopub.status.busy":"2022-08-21T10:21:55.322131Z","iopub.status.idle":"2022-08-21T10:21:55.328779Z","shell.execute_reply":"2022-08-21T10:21:55.327481Z","shell.execute_reply.started":"2022-08-21T10:21:55.322455Z"},"id":"neO0GCjVXRKN","trusted":true},"outputs":[],"source":["def our_standardization(text_data):\n","  lowercase = tf.strings.lower(text_data) # convert to lowercase\n","  remove_html = tf.strings.regex_replace(lowercase, '<br />', ' ') # remove HTML tags\n","  pattern_remove_punctuation = '[%s]' % re.escape(string.punctuation) # pattern to remove punctuation\n","  remove_punct = tf.strings.regex_replace(remove_html, pattern_remove_punctuation, '') # apply pattern\n","  remove_double_spaces = tf.strings.regex_replace(remove_punct, '\\s+', ' ') # remove double space\n","  return remove_double_spaces"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:22:00.749352Z","iopub.status.busy":"2022-08-21T10:22:00.749007Z","iopub.status.idle":"2022-08-21T10:22:03.278215Z","shell.execute_reply":"2022-08-21T10:22:03.277245Z","shell.execute_reply.started":"2022-08-21T10:22:00.749322Z"},"id":"vKXEnqhiX6x2","outputId":"c5169b05-08f0-4479-8973-df1c787779ce","trusted":true},"outputs":[],"source":["our_standardization(train_desc[0])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:22:04.665006Z","iopub.status.busy":"2022-08-21T10:22:04.664110Z","iopub.status.idle":"2022-08-21T10:22:04.709687Z","shell.execute_reply":"2022-08-21T10:22:04.708770Z","shell.execute_reply.started":"2022-08-21T10:22:04.664960Z"},"id":"KXR3N4xgyR_9","trusted":true},"outputs":[],"source":["from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","\n","vocab_size = 10000\n","seq_length = 500\n","\n","# Create a vectorization layer\n","vectorize_layer = TextVectorization(\n","    standardize = our_standardization,\n","    max_tokens = vocab_size,\n","    output_sequence_length = seq_length\n","    )"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:22:20.032495Z","iopub.status.busy":"2022-08-21T10:22:20.029506Z","iopub.status.idle":"2022-08-21T10:22:20.042152Z","shell.execute_reply":"2022-08-21T10:22:20.041063Z","shell.execute_reply.started":"2022-08-21T10:22:20.032449Z"},"id":"JbOBJHa2c1nk","outputId":"172ffda2-f1da-477b-c783-6a17fae1df61","trusted":true},"outputs":[],"source":["desc1, desc2 = train_desc[2], train_desc[3]\n","print(desc1+'\\n\\n'+desc2)\n","\n","ngbr1, ngbr2 = train_ngbr[2], train_ngbr[3]\n","print(ngbr1+'\\n\\n'+ngbr2)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T10:24:27.119548Z","iopub.status.busy":"2022-08-21T10:24:27.119007Z","iopub.status.idle":"2022-08-21T10:24:28.247474Z","shell.execute_reply":"2022-08-21T10:24:28.244830Z","shell.execute_reply.started":"2022-08-21T10:24:27.119509Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi\n","\n","tf.test.is_gpu_available()"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T11:49:38.541979Z","iopub.status.busy":"2022-08-21T11:49:38.541012Z","iopub.status.idle":"2022-08-21T11:49:38.591117Z","shell.execute_reply":"2022-08-21T11:49:38.590057Z","shell.execute_reply.started":"2022-08-21T11:49:38.541937Z"},"id":"ovNC3cDWfmK9","outputId":"38ea07cd-25cc-4a2d-d5f1-3c2e33bbe085","trusted":true},"outputs":[],"source":["emb_size = 32\n","rnn_units = 16\n","\n","\n","def create_text_model(text_list):\n","    model = Sequential()\n","    model.add(Input(shape=(1,), dtype=tf.string))\n","    vectorize_layer.adapt(text_list)\n","    model.add(vectorize_layer)\n","    model.add(Embedding(input_dim=vocab_size, output_dim=emb_size))\n","    model.add(LSTM(rnn_units, return_sequences=False))\n","    model.add(Dense(1, activation=\"relu\"))\n","    return model\n","\n","def create_combined_model(X):\n","    X = Flatten()(X)\n","    X = Dense(1, activation=\"linear\")(X)\n","    print(X.shape)\n","    return X\n","\n","def create_model():\n","    \n","    ### Initialize Input layers\n","    input_desc = Input(shape=(1,), dtype=tf.string)\n","    input_ngbr = Input(shape=(1,), dtype=tf.string)\n","    \n","    ### Create Vectorisation models from text features\n","    desc_model = create_text_model(train_desc)\n","    ngbr_model = create_text_model(train_ngbr)\n","#     combined_model = create_combined_model()\n","    \n","    ### Create Data flow\n","    emb_desc = desc_model(input_desc)\n","    emb_ngbr = ngbr_model(input_ngbr)\n","    concat_combined = Concatenate()([emb_desc,emb_ngbr])\n","    print(concat_combined.shape)\n","    output = create_combined_model(concat_combined)\n","    \n","    ### Finalize the model\n","    model = Model(inputs = [input_desc, input_ngbr], outputs = output)\n","    model.compile(optimizer='adam',loss='mse', metrics=['mae'])\n","    return model\n","\n","\n","\n","\n","\n","\n","\n","\n","# desc_embedded = desc_model.predict([desc1,desc2])\n","# ngbr_model = create_text_model(train_ngbr)\n","\n","# dense_desc = desc_model([desc2])\n","# dense_ngbr = ngbr_model([ngbr2])\n","\n","# concatenated_values = layers.Concatenate([dense_model, ngbr_model])\n","\n","# print(concatenated_values.shape)\n","\n","# def create_model(text_features_list):\n","#   vec_model = \n","#   for feature in text_features_list:\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZJkZeLmyc4m","outputId":"bc1eb455-92a4-4e4d-97a4-5e7ee2fc4d28"},"outputs":[],"source":["# Create model with LSTM\n","emb_size = 100\n","rnn_units = 64\n","\n","input_ngbr = tf.keras.Input(shape=(seq_length,), dtype=\"int64\") \n","input_desc = tf.keras.Input(shape=(seq_length,), dtype=\"int64\") \n","emb_desc = layers.Embedding(input_dim=vocab_size, output_dim=emb_size)(input_desc) \n","x_desc = layers.GRU(rnn_units)(emb_desc)\n","dense_desc = layers.Dense(1, activation=\"relu\")(x_desc)\n","\n","emb_ngbr = layers.Embedding(input_dim=vocab_size, output_dim=emb_size)(input_ngbr) \n","x_ngbr = layers.GRU(rnn_units)(emb_ngbr)\n","dense_ngbr = layers.Dense(1, activation=\"relu\")(x_ngbr)\n","\n","concat = concatenate([dense_desc, dense_ngbr])\n","norm = layers.BatchNormalization()(concat)\n","dense_full = Dense(128, activation=\"relu\")(norm)\n","#dense_full = Dense(64, activation=\"relu\")(dense_full)\n","output_layer = Dense(1, activation=\"relu\")(dense_full)\n","\n","\n","model = tf.keras.Model(inputs = [input_desc, input_ngbr], outputs = output_layer) \n","\n","model.compile(optimizer='adam', \n","    loss='mse', \n","    metrics=['mae']) \n","model.summary()"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T11:45:44.268574Z","iopub.status.busy":"2022-08-21T11:45:44.267969Z","iopub.status.idle":"2022-08-21T11:45:44.292924Z","shell.execute_reply":"2022-08-21T11:45:44.291766Z","shell.execute_reply.started":"2022-08-21T11:45:44.268540Z"},"trusted":true},"outputs":[],"source":["# tf.convert_to_tensor([zip(train_desc,train_ngbr))\n","y_train = tf.convert_to_tensor(y_train)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T12:00:50.616792Z","iopub.status.busy":"2022-08-21T12:00:50.616158Z","iopub.status.idle":"2022-08-21T12:00:50.634243Z","shell.execute_reply":"2022-08-21T12:00:50.633182Z","shell.execute_reply.started":"2022-08-21T12:00:50.616734Z"},"trusted":true},"outputs":[],"source":["train_text_ds_raw = tf.data.Dataset.from_tensor_slices(\n","            tf.cast(train_features.values, tf.string)\n",") \n","train_cat_ds_raw = tf.data.Dataset.from_tensor_slices(\n","            tf.cast(train_targets.values, tf.int64),\n","\n",") \n","\n","\n","def convert_text_input(sample):\n","    text = sample\n","    text = tf.expand_dims(text, -1)  \n","    #return tf.squeeze(vectorize_layer(text))\n","    return tf.squeeze(vectorize_layer(text))\n","\n","convert_text_input([\"what is this misery\",\"what is your story\"]).shape"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T12:12:17.219588Z","iopub.status.busy":"2022-08-21T12:12:17.219203Z","iopub.status.idle":"2022-08-21T12:18:41.882868Z","shell.execute_reply":"2022-08-21T12:18:41.881803Z","shell.execute_reply.started":"2022-08-21T12:12:17.219556Z"},"id":"u1Mo2U2P5BcS","outputId":"d1de1e16-2c54-4ea8-ef25-f10996a6e02c","trusted":true},"outputs":[],"source":["# model = create_model()\n","# desc_model = create_text_model(train_desc)\n","\n","# print(desc_model.summary())\n","# desc_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","story = model.fit(\n","   [train_desc, train_ngbr],\n","   y_train,\n","#     validation_split=0.2,\n","    epochs = 5,\n","    batch_size = 32,\n","    verbose =1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cddlmWSxYtH6"},"outputs":[],"source":["?model.fit"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T12:18:41.885827Z","iopub.status.busy":"2022-08-21T12:18:41.885422Z","iopub.status.idle":"2022-08-21T12:19:23.881327Z","shell.execute_reply":"2022-08-21T12:19:23.880233Z","shell.execute_reply.started":"2022-08-21T12:18:41.885789Z"},"id":"Domc2C7WSb-H","outputId":"8edd6dd0-9118-4b74-cdc7-b6b2999bbc6f","trusted":true},"outputs":[],"source":["preds = pd.DataFrame(model.predict([train_desc,train_ngbr]), columns=[\"price\"], index=train.index)"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T12:19:23.883486Z","iopub.status.busy":"2022-08-21T12:19:23.882799Z","iopub.status.idle":"2022-08-21T12:19:23.900847Z","shell.execute_reply":"2022-08-21T12:19:23.899928Z","shell.execute_reply.started":"2022-08-21T12:19:23.883435Z"},"id":"Tu4sBsNBd-_6","outputId":"117ebf69-8a15-44cc-e35a-7af367444a7d","trusted":true},"outputs":[],"source":["preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4mhAT4MiYTwd"},"outputs":[],"source":["?model.predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbKwWKH45BcS","outputId":"a7422c58-29d0-4078-b506-7aa5be1567a7"},"outputs":[],"source":["pred_ff_train = model.predict(X_train)\n","pred_ff_test = model.predict(X_val)\n","print('Mean Absolute Error:', metrics.mean_absolute_error(y_val,pred_ff_test))  \n","print('Mean Squared Error:', metrics.mean_squared_error(y_val,pred_ff_test))  \n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val,pred_ff_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fanYaQ5n5BcT","outputId":"e959bbc7-ad5a-471c-dafa-27a7488aa370"},"outputs":[],"source":["test_summary = vectorize_layer(test_summary)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agzsXwYX5BcX","outputId":"7415bbc1-8e94-4e26-f33f-1e45cd843d4d"},"outputs":[],"source":["pred_ff_kaggle = model.predict(test_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jg_ccU3_5BcX","outputId":"cb119750-18ea-4399-afcc-2af6225ffd25"},"outputs":[],"source":["pred_ff_kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8shbM3Uv5BcX","outputId":"1fab0e89-9b72-4eef-bee9-958eb75dfee2"},"outputs":[],"source":["pred_ff_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUtrhsqe5BcY","outputId":"eb6396c1-266f-4d92-9a4d-98d8a8a720d6"},"outputs":[],"source":["vocab_size = 10000\n","seq_length = 500\n","input = tf.keras.Input(shape=(seq_length,), dtype=\"int64\") \n","emb = layers.Embedding(input_dim=vocab_size, output_dim=emb_size, mask_zero=True)(input) \n","x = layers.Bidirectional(layers.LSTM(rnn_units))(emb)\n","x = layers.Dropout(0.5)(x)\n","output = layers.Dense(1, activation=\"relu\")(x)\n","model = tf.keras.Model(input, output) \n","\n","model.compile(optimizer='rmsprop', \n","    loss='mse', \n","    metrics=['mae']) \n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRJQSmLw5BcY","outputId":"af6e211c-232d-4e2d-de4a-afffc9ec8ecb"},"outputs":[],"source":["model.fit(\n","    X_train, \n","    y_train, \n","    validation_data=(X_val, y_val),\n","    epochs = 2,\n","    batch_size = 128)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejCPjqBZ5BcZ"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"}}},"nbformat":4,"nbformat_minor":4}
